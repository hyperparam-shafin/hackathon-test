{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r'/home/xavient/wns_hack')\n",
    "\n",
    "#machine learning libraries\n",
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, recall_score, roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "iter_no = 5\n",
    "gp_params = {'alpha': 1e-5}\n",
    "cv_splits = 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def treesCV(eta, gamma,max_depth,min_child_weight,subsample,colsample_bytree,n_estimators):\n",
    "    #function for cross validation gradient boosted trees\n",
    "    return cross_val_score(xgb.XGBRegressor(objective='binary:logistic',\n",
    "    \t\t\t\t\t\t\t\t\t\t\ttree_method = 'hist',\n",
    "                                                learning_rate=max(eta,0),\n",
    "                                                gamma=max(gamma,0),\n",
    "                                                max_depth=int(max_depth),\n",
    "                                                min_child_weight=int(min_child_weight),\n",
    "                                                silent=True,\n",
    "                                                subsample=max(min(subsample,1),0.0001),\n",
    "                                                colsample_bytree=max(min(colsample_bytree,1),0.0001),\n",
    "                                                n_estimators=int(n_estimators),\n",
    "                                                seed=42,nthread=-1), X=X_train, y=y_train, scoring=None, cv=cv_splits, n_jobs=-1).mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_prep(data_df):\n",
    "\n",
    "    #how to handle types\n",
    "    data_df_num = data_df.select_dtypes(exclude=object)\n",
    "    data_df_obj = data_df.select_dtypes(include=object)\n",
    "\n",
    "    #how to handle nan\n",
    "    data_df_num = data_df_num.fillna(data_df_num.mean())\n",
    "\n",
    "    #get dummy variables\n",
    "    data_df_obj = data_df_obj.fillna(\"UNKNOWN\")\n",
    "    data_df_obj = pd.get_dummies(data_df_obj, dummy_na=True)\n",
    "\n",
    "    data_concat = pd.concat([data_df_num, data_df_obj],axis=1)\n",
    "\n",
    "    return data_concat.drop(['department_nan','region_region_18','region_nan','education_nan',\n",
    "                             'gender_nan','recruitment_channel_nan','region_region_10','region_region_12',\n",
    "                             'region_region_24', 'region_region_31', 'region_region_33'],axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reading data\n",
    "data_train = pd.read_csv('train.csv', sep=',',encoding=\"ISO-8859-1\")\n",
    "data_train = data_prep(data_train)\n",
    "\n",
    "data_pred = pd.read_csv('test.csv', sep=',',encoding=\"ISO-8859-1\")\n",
    "data_pred = data_prep(data_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split doesnt actually split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data_train.drop(['is_promoted','employee_id'],axis=1)), np.array(data_train['is_promoted']), test_size=0, random_state=42)\n",
    "X_test1 = data_pred.drop(['employee_id'],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   n_estimators |   subsample | \n",
      "    1 | 01m08s | \u001b[35m   0.29041\u001b[0m | \u001b[32m            0.5117\u001b[0m | \u001b[32m   0.1253\u001b[0m | \u001b[32m  11.3192\u001b[0m | \u001b[32m   555.6915\u001b[0m | \u001b[32m            0.4675\u001b[0m | \u001b[32m     1726.6769\u001b[0m | \u001b[32m     0.4378\u001b[0m | \n",
      "    2 | 01m18s | \u001b[35m   0.29305\u001b[0m | \u001b[32m            0.5400\u001b[0m | \u001b[32m   0.1161\u001b[0m | \u001b[32m  10.3380\u001b[0m | \u001b[32m   558.0828\u001b[0m | \u001b[32m            0.6239\u001b[0m | \u001b[32m     1625.5646\u001b[0m | \u001b[32m     0.5675\u001b[0m | \n",
      "    3 | 01m22s |    0.29296 |             0.5327 |    0.1099 |   10.4878 |    555.4355 |             0.4020 |      1771.1170 |      0.5459 | \n",
      "    4 | 01m25s |    0.29268 |             0.5115 |    0.1242 |   10.7298 |    556.6395 |             0.4478 |      1794.3355 |      0.5927 | \n",
      "    5 | 01m06s |    0.29029 |             0.5365 |    0.1535 |   12.8477 |    557.5007 |             0.4561 |      1649.0193 |      0.4419 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   n_estimators |   subsample | \n",
      "    6 | 01m28s |    0.29072 |             0.5372 |    0.1037 |   12.9639 |    550.4812 |             0.6086 |      1600.0096 |      0.5268 | \n",
      "    7 | 01m23s |    0.29179 |             0.5251 |    0.1214 |   10.2658 |    550.3161 |             0.6919 |      1799.9903 |      0.4014 | \n",
      "    8 | 01m35s |    0.29204 |             0.5288 |    0.1483 |   11.3427 |    559.9759 |             0.4115 |      1799.9112 |      0.5070 | \n",
      "    9 | 01m18s |    0.29003 |             0.5135 |    0.1536 |   12.4573 |    559.8186 |             0.5669 |      1600.0319 |      0.4229 | \n",
      "   10 | 01m33s |    0.29054 |             0.5370 |    0.1304 |   11.0439 |    550.0243 |             0.5542 |      1799.9868 |      0.4397 | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Bayesian Hyper parameter optimization of gradient boosted trees\n",
    "treesBO = BayesianOptimization(treesCV,{'eta':(0.10,0.16),\n",
    "                                        'gamma':(10,13),\n",
    "                                        'max_depth':(550,560),\n",
    "                                        'min_child_weight':(0.4,0.7),\n",
    "                                        'subsample':(0.4,0.6),\n",
    "                                        'colsample_bytree':(0.50,0.55),\n",
    "                                        'n_estimators':(1600,1800)})\n",
    "treesBO.maximize(n_iter=iter_no, **gp_params)\n",
    "tree_best = treesBO.res['max']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_params': {'colsample_bytree': 0.5400425501321214,\n",
       "  'eta': 0.1161050737052063,\n",
       "  'gamma': 10.337991942759661,\n",
       "  'max_depth': 558.0827955992903,\n",
       "  'min_child_weight': 0.6239178646164122,\n",
       "  'n_estimators': 1625.5645743297848,\n",
       "  'subsample': 0.5674805908320731},\n",
       " 'max_val': 0.2930468350310664}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train tree with best paras\n",
    "trees_model = xgb.XGBRegressor(objective='binary:logistic',\n",
    "                                tree_method = 'hist',\n",
    "                                seed=42,\n",
    "                                learning_rate=max(tree_best['max_params']['eta'],0),\n",
    "                                gamma=max(tree_best['max_params']['gamma'],0),\n",
    "                                max_depth=int(tree_best['max_params']['max_depth']),\n",
    "                                min_child_weight=int(tree_best['max_params']['min_child_weight']),\n",
    "                                silent=True,\n",
    "                                subsample=max(min(tree_best['max_params']['subsample'],1),0.0001),\n",
    "                                colsample_bytree=max(min(tree_best['max_params']['colsample_bytree'],1),0.0001),\n",
    "                                n_estimators=int(tree_best['max_params']['n_estimators']),nthread=-1)\n",
    "trees_model.fit(X_train, y_train)\n",
    "y_hat1 = trees_model.predict(np.array(X_test1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=np.where(y_hat1>=.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split doesnt actually split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(data_train.drop(['is_promoted','employee_id'],axis=1)), np.array(data_train['is_promoted']), test_size=0.2, random_state=42)\n",
    "X_test1 = data_pred.drop(['employee_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lgb(train_X, train_y, val_X, val_y):\n",
    "    params = {\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : \"auc\",\n",
    "    \"num_leaves\" : 40,\n",
    "    \"learning_rate\" : 0.005,\n",
    "    \"bagging_fraction\" : 0.6,\n",
    "    \"feature_fraction\" : 0.6,\n",
    "    \"bagging_frequency\" : 6,\n",
    "    \"bagging_seed\" : 42,\n",
    "    \"verbosity\" : -1,\n",
    "    \"seed\": 42\n",
    "    }\n",
    "\n",
    "    lgtrain = lgb.Dataset(train_X, label = train_y)\n",
    "    lgval = lgb.Dataset(val_X, label = val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 5000, valid_sets = [lgtrain, lgval], early_stopping_rounds = 100, \n",
    "              verbose_eval = 150, evals_result = evals_result)\n",
    "    return model, evals_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM performance\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's auc: 0.910793\tvalid_1's auc: 0.92234\n",
      "LightGBM Training Completed...\n",
      "################################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"LGBM performance\")\n",
    "model_lgbm, evals_result = run_lgb(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"LightGBM Training Completed...\")\n",
    "print(\"################################################\")\n",
    "y_hat2 = model_lgbm.predict(np.array(X_test1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = (y_hat1+y_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=np.where(yhats>=.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame({'employee_id':np.array(data_pred['employee_id']),'is_promoted':yhat})\n",
    "\n",
    "#write to file for submission\n",
    "submission.to_csv('submission.csv',sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  is_promoted\n",
       "0         8724            0\n",
       "1        74430            0\n",
       "2        72255            0\n",
       "3        38562            0\n",
       "4        64486            0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02543787, 0.08590492, 0.06422018, 0.06338616, 0.03753128,\n",
       "       0.01834862, 0.24812344, 0.02418682, 0.02293578, 0.01709758,\n",
       "       0.01084237, 0.02919099, 0.03294412, 0.01793161, 0.03211009,\n",
       "       0.02251877, 0.00333611, 0.00959133, 0.00375313, 0.00542118,\n",
       "       0.0058382 , 0.00458716, 0.00750626, 0.00333611, 0.00792327,\n",
       "       0.00375313, 0.0058382 , 0.01959967, 0.00708924, 0.00667223,\n",
       "       0.00750626, 0.00542118, 0.0087573 , 0.00750626, 0.00333611,\n",
       "       0.00333611, 0.00625521, 0.00625521, 0.01209341, 0.0029191 ,\n",
       "       0.00417014, 0.01334445, 0.00333611, 0.0058382 , 0.00959133,\n",
       "       0.00250209, 0.00708924, 0.00792327, 0.01292744, 0.00625521,\n",
       "       0.00333611, 0.00959133, 0.00375313], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_trainings', 'age', 'previous_year_rating', 'length_of_service',\n",
       "       'KPIs_met >80%', 'awards_won?', 'avg_training_score',\n",
       "       'department_Analytics', 'department_Finance', 'department_HR',\n",
       "       'department_Legal', 'department_Operations', 'department_Procurement',\n",
       "       'department_R&D', 'department_Sales & Marketing',\n",
       "       'department_Technology', 'region_region_1', 'region_region_11',\n",
       "       'region_region_13', 'region_region_14', 'region_region_15',\n",
       "       'region_region_16', 'region_region_17', 'region_region_19',\n",
       "       'region_region_2', 'region_region_20', 'region_region_21',\n",
       "       'region_region_22', 'region_region_23', 'region_region_25',\n",
       "       'region_region_26', 'region_region_27', 'region_region_28',\n",
       "       'region_region_29', 'region_region_3', 'region_region_30',\n",
       "       'region_region_32', 'region_region_34', 'region_region_4',\n",
       "       'region_region_5', 'region_region_6', 'region_region_7',\n",
       "       'region_region_8', 'region_region_9', 'education_Bachelor's',\n",
       "       'education_Below Secondary', 'education_Master's & above',\n",
       "       'education_UNKNOWN', 'gender_f', 'gender_m',\n",
       "       'recruitment_channel_other', 'recruitment_channel_referred',\n",
       "       'recruitment_channel_sourcing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.drop(['is_promoted','employee_id'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
